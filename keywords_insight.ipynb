{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 文献关键词探究\n",
    "\n",
    "实现的功能：\n",
    "- 输入想要探究的关键词，生成与该关键词经常同时出现的频率最高的10个关键词\n",
    "- 输出该关键词所有的年份的高引论文5篇和最近3年的高引论文5篇\n",
    "- 输出该关键词发表论文最多的机构\n"
   ],
   "id": "5b6c9cfd0ebb9175"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:51.010949Z",
     "start_time": "2025-05-10T09:56:50.998975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:51.658078Z",
     "start_time": "2025-05-10T09:56:51.644564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设置matplotlib中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ],
   "id": "e967ca6443d38ffb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:53.227976Z",
     "start_time": "2025-05-10T09:56:51.862363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 下载nltk词库（如果首次使用）\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ],
   "id": "e82db060222ae057",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:53.243877Z",
     "start_time": "2025-05-10T09:56:53.235236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"加载CSV数据文件\"\"\"\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    print(f\"数据集大小: {df.shape}\")\n",
    "    print(f\"数据集列名: {df.columns.tolist()}\")\n",
    "    return df"
   ],
   "id": "8771a6b75533f380",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:54.773529Z",
     "start_time": "2025-05-10T09:56:54.758863Z"
    }
   },
   "cell_type": "code",
   "source": "insight_keywords = ['continuous fibers', 'path planning method', 'robot programming', 'optimization', 'topology optimisation']",
   "id": "c3db4d28cabd509c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:54.804832Z",
     "start_time": "2025-05-10T09:56:54.790079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = './results/CFpathPlanning101_20250510_17/CFpathPlanning101_replaced_synonyms.csv'\n",
    "save_path = './results'\n",
    "df = load_data(file_path)"
   ],
   "id": "34ec6ee59cdc178d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小: (101, 26)\n",
      "数据集列名: ['作者', 'Author full names', '作者 ID', '文献标题', '年份', '来源出版物名称', '卷', '期', '论文编号', '起始页码', '结束页码', '页码计数', '施引文献', 'DOI', '链接', '归属机构', '带归属机构的作者', '摘要', '作者关键字', '索引关键字', '通讯地址', '文献类型', '出版阶段', '开放获取', '来源出版物', 'EID']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:54.835241Z",
     "start_time": "2025-05-10T09:56:54.821111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_filename = os.path.basename(file_path)\n",
    "file_name_without_ext = os.path.splitext(base_filename)[0]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H\")\n",
    "output_dir = f\"{save_path}/{file_name_without_ext}_{timestamp}\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"创建输出目录: {output_dir}\")\n"
   ],
   "id": "87d744f21abfbc33",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:54.865384Z",
     "start_time": "2025-05-10T09:56:54.851196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_keywords(keywords_str):\n",
    "    \"\"\"清理关键词字符串并返回关键词列表\"\"\"\n",
    "    if pd.isna(keywords_str) or keywords_str == '':\n",
    "        return []\n",
    "    # 移除引号和额外的空格，并拆分成列表\n",
    "    return [k.strip().lower() for k in re.split(r'[;,]', str(keywords_str)) if k.strip()]"
   ],
   "id": "d36daedcf3e35993",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:54.896016Z",
     "start_time": "2025-05-10T09:56:54.881103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_all_keywords(df):\n",
    "    \"\"\"从作者关键词和索引关键词中提取所有关键词\"\"\"\n",
    "    author_keywords = []\n",
    "    for keywords in df['作者关键字'].dropna():\n",
    "        author_keywords.extend(clean_keywords(keywords))\n",
    "\n",
    "    index_keywords = []\n",
    "    for keywords in df['索引关键字'].dropna():\n",
    "        index_keywords.extend(clean_keywords(keywords))\n",
    "\n",
    "    # 合并两种关键词\n",
    "    all_keywords = author_keywords + index_keywords\n",
    "    return all_keywords"
   ],
   "id": "c4ec487eccbd5a04",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:54.927244Z",
     "start_time": "2025-05-10T09:56:54.912789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_cooccurring_keywords(df, target_keyword, top_n=10):\n",
    "    \"\"\"找到与目标关键词经常共现的其他关键词\"\"\"\n",
    "    cooccurring_keywords = []\n",
    "\n",
    "    # 创建一个包含作者关键词和索引关键词的列\n",
    "    df['all_keywords'] = df.apply(\n",
    "        lambda row: clean_keywords(str(row['作者关键字'])) + clean_keywords(str(row['索引关键字'])),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 筛选包含目标关键词的文章\n",
    "    target_keyword_lower = target_keyword.lower()\n",
    "    relevant_papers = df[df['all_keywords'].apply(lambda keywords: target_keyword_lower in [k.lower() for k in keywords])]\n",
    "\n",
    "    print(f\"包含关键词 '{target_keyword}' 的论文数量: {len(relevant_papers)}\")\n",
    "\n",
    "    if len(relevant_papers) == 0:\n",
    "        return []\n",
    "\n",
    "    # 从这些论文中提取所有其他关键词并计数\n",
    "    for keywords in relevant_papers['all_keywords']:\n",
    "        keywords_without_target = [k for k in keywords if k.lower() != target_keyword_lower]\n",
    "        cooccurring_keywords.extend(keywords_without_target)\n",
    "\n",
    "    # 计算频率\n",
    "    keyword_counts = Counter(cooccurring_keywords)\n",
    "\n",
    "    # 筛选出现次数大于等于2的关键词\n",
    "    filtered_keyword_counts = Counter({k: v for k, v in keyword_counts.items() if v >= 2})\n",
    "\n",
    "    # 如果没有符合条件的关键词，返回空列表\n",
    "    if not filtered_keyword_counts:\n",
    "        return []\n",
    "\n",
    "    # 返回出现频率最高的top_n个关键词\n",
    "    top_keywords_with_counts = filtered_keyword_counts.most_common(top_n)\n",
    "\n",
    "    return top_keywords_with_counts\n"
   ],
   "id": "84dabccfe3983961",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:54.958346Z",
     "start_time": "2025-05-10T09:56:54.943976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_highly_cited_papers(df, target_keyword, top_n=5):\n",
    "    \"\"\"获取关键词相关的高引论文\"\"\"\n",
    "    # 创建一个包含作者关键词和索引关键词的列\n",
    "    if 'all_keywords' not in df.columns:\n",
    "        df['all_keywords'] = df.apply(\n",
    "            lambda row: clean_keywords(str(row['作者关键字'])) + clean_keywords(str(row['索引关键字'])),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # 筛选包含目标关键词的文章\n",
    "    target_keyword_lower = target_keyword.lower()\n",
    "    relevant_papers = df[df['all_keywords'].apply(lambda keywords: target_keyword_lower in [k.lower() for k in keywords])]\n",
    "\n",
    "    if len(relevant_papers) == 0:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # 将'施引文献'转换为数值型\n",
    "    relevant_papers['citation_count'] = pd.to_numeric(relevant_papers['施引文献'], errors='coerce').fillna(0)\n",
    "\n",
    "    # 按引用次数排序\n",
    "    all_time_top_papers = relevant_papers.sort_values('citation_count', ascending=False).head(top_n)\n",
    "\n",
    "    # 获取当前年份\n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    # 筛选最近3年的论文\n",
    "    recent_papers = relevant_papers[relevant_papers['年份'] >= current_year - 3]\n",
    "    recent_top_papers = recent_papers.sort_values('citation_count', ascending=False).head(top_n)\n",
    "\n",
    "    return all_time_top_papers, recent_top_papers"
   ],
   "id": "197089ad4b32bbc2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:55.003428Z",
     "start_time": "2025-05-10T09:56:54.988713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_top_institutions(df, target_keyword, top_n=10):\n",
    "    \"\"\"找到发表与关键词相关论文最多的机构\"\"\"\n",
    "    # 创建一个包含作者关键词和索引关键词的列\n",
    "    if 'all_keywords' not in df.columns:\n",
    "        df['all_keywords'] = df.apply(\n",
    "            lambda row: clean_keywords(str(row['作者关键字'])) + clean_keywords(str(row['索引关键字'])),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    # 筛选包含目标关键词的文章\n",
    "    target_keyword_lower = target_keyword.lower()\n",
    "    relevant_papers = df[df['all_keywords'].apply(lambda keywords: target_keyword_lower in [k.lower() for k in keywords])]\n",
    "\n",
    "    if len(relevant_papers) == 0:\n",
    "        return []\n",
    "\n",
    "    # 提取所有机构\n",
    "    all_institutions = []\n",
    "    for affiliation in relevant_papers['归属机构'].dropna():\n",
    "        # 使用分号拆分多个机构\n",
    "        institutions = [inst.strip() for inst in str(affiliation).split(';') if inst.strip()]\n",
    "        all_institutions.extend(institutions)\n",
    "\n",
    "    # 统计每个机构的论文数量\n",
    "    institution_counts = Counter(all_institutions)\n",
    "\n",
    "    # 返回发表论文最多的top_n个机构\n",
    "    top_institutions = institution_counts.most_common(top_n)\n",
    "\n",
    "    return top_institutions"
   ],
   "id": "818eba79a23565d2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:55.018500Z",
     "start_time": "2025-05-10T09:56:55.005210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_keyword_report(df, keyword, output_dir):\n",
    "    \"\"\"为指定关键词生成分析报告\"\"\"\n",
    "    # 创建报告文件名\n",
    "    report_filename = f\"{output_dir}/keyword_analysis_{keyword.replace(' ', '_')}.txt\"\n",
    "\n",
    "    # 查找共现关键词\n",
    "    cooccurring_keywords = find_cooccurring_keywords(df, keyword)\n",
    "\n",
    "    # 查找高引论文\n",
    "    all_time_top_papers, recent_top_papers = find_highly_cited_papers(df, keyword)\n",
    "\n",
    "    # 查找顶级机构\n",
    "    top_institutions = find_top_institutions(df, keyword)\n",
    "\n",
    "    # 生成报告\n",
    "    with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Keyword Analysis Report: '{keyword}'\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "\n",
    "        # 1. 写入共现关键词\n",
    "        f.write(\"1. Top 10 Co-occurring Keywords:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if cooccurring_keywords:\n",
    "            for i, (kw, count) in enumerate(cooccurring_keywords, 1):\n",
    "                f.write(f\"{i}. {kw} (Count: {count})\\n\")\n",
    "        else:\n",
    "            f.write(\"No co-occurring keywords found.\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        # 2. 写入所有时期的高引论文\n",
    "        f.write(\"2. Top 5 Highly Cited Papers (All Time):\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if not all_time_top_papers.empty:\n",
    "            for i, (_, paper) in enumerate(all_time_top_papers.iterrows(), 1):\n",
    "                f.write(f\"{i}. Title: {paper['文献标题']}\\n\")\n",
    "                f.write(f\"   Authors: {paper['作者'] if not pd.isna(paper['作者']) else 'N/A'}\\n\")\n",
    "                f.write(f\"   Year: {paper['年份']}\\n\")\n",
    "                f.write(f\"   Citations: {int(paper['citation_count'])}\\n\")\n",
    "                f.write(f\"   DOI: {paper['DOI'] if not pd.isna(paper['DOI']) else 'N/A'}\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"No papers found.\\n\\n\")\n",
    "\n",
    "        # 3. 写入近3年的高引论文\n",
    "        current_year = datetime.now().year\n",
    "        f.write(f\"3. Top 5 Highly Cited Papers (Last 3 Years, {current_year-3}-{current_year}):\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if not recent_top_papers.empty:\n",
    "            for i, (_, paper) in enumerate(recent_top_papers.iterrows(), 1):\n",
    "                f.write(f\"{i}. Title: {paper['文献标题']}\\n\")\n",
    "                f.write(f\"   Authors: {paper['作者'] if not pd.isna(paper['作者']) else 'N/A'}\\n\")\n",
    "                f.write(f\"   Year: {paper['年份']}\\n\")\n",
    "                f.write(f\"   Citations: {int(paper['citation_count'])}\\n\")\n",
    "                f.write(f\"   DOI: {paper['DOI'] if not pd.isna(paper['DOI']) else 'N/A'}\\n\\n\")\n",
    "        else:\n",
    "            f.write(\"No recent papers found.\\n\\n\")\n",
    "\n",
    "        # 4. 写入顶级机构\n",
    "        f.write(\"4. Top Institutions Publishing Papers on this Keyword:\\n\")\n",
    "        f.write(\"-\" * 40 + \"\\n\")\n",
    "        if top_institutions:\n",
    "            for i, (inst, count) in enumerate(top_institutions, 1):\n",
    "                f.write(f\"{i}. {inst} (Paper Count: {count})\\n\")\n",
    "        else:\n",
    "            f.write(\"No institution data available.\\n\")\n",
    "\n",
    "    print(f\"报告已生成: {report_filename}\")\n",
    "\n",
    "    # 返回报告路径和生成的图表路径\n",
    "    return report_filename"
   ],
   "id": "5a53dbb9f36ca74f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:55.049322Z",
     "start_time": "2025-05-10T09:56:55.035001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def analyze_multiple_keywords(df, keywords, output_dir):\n",
    "    \"\"\"分析多个关键词并生成报告\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        print(f\"\\n正在分析关键词: {keyword}\")\n",
    "        report_path = generate_keyword_report(df, keyword, output_dir)\n",
    "        results.append((keyword, report_path))\n",
    "\n",
    "    return results"
   ],
   "id": "e4b731352132e820",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T09:56:55.095092Z",
     "start_time": "2025-05-10T09:56:55.065712Z"
    }
   },
   "cell_type": "code",
   "source": "results = analyze_multiple_keywords(df, insight_keywords, output_dir)",
   "id": "2a7486b752bfc132",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在分析关键词: continuous fibers\n",
      "包含关键词 'continuous fibers' 的论文数量: 10\n",
      "报告已生成: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_continuous_fibers.txt\n",
      "\n",
      "正在分析关键词: path planning method\n",
      "包含关键词 'path planning method' 的论文数量: 16\n",
      "报告已生成: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_path_planning_method.txt\n",
      "\n",
      "正在分析关键词: robot programming\n",
      "包含关键词 'robot programming' 的论文数量: 15\n",
      "报告已生成: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_robot_programming.txt\n",
      "\n",
      "正在分析关键词: optimization\n",
      "包含关键词 'optimization' 的论文数量: 6\n",
      "报告已生成: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_optimization.txt\n",
      "\n",
      "正在分析关键词: topology optimisation\n",
      "包含关键词 'topology optimisation' 的论文数量: 3\n",
      "报告已生成: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_topology_optimisation.txt\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:02:00.332275Z",
     "start_time": "2025-05-10T10:02:00.320276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    html_source_files = []\n",
    "    print(\"\\n分析完成！生成的报告:\")\n",
    "    for keyword, report_path in results:\n",
    "        print(f\"- {keyword}: {report_path}\")\n",
    "        html_source_files.append(report_path)"
   ],
   "id": "d40ba00bdc968bfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "分析完成！生成的报告:\n",
      "- continuous fibers: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_continuous_fibers.txt\n",
      "- path planning method: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_path_planning_method.txt\n",
      "- robot programming: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_robot_programming.txt\n",
      "- optimization: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_optimization.txt\n",
      "- topology optimisation: ./results/CFpathPlanning101_replaced_synonyms_20250510_17/keyword_analysis_topology_optimisation.txt\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 生成HTML仪表\n",
   "id": "e561146e209aecf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:02:33.816123Z",
     "start_time": "2025-05-10T10:02:33.801934Z"
    }
   },
   "cell_type": "code",
   "source": "output_file = os.path.join(output_dir, \"keyword_analysis_dashboard.html\")",
   "id": "c87db123002431db",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:06:09.090075Z",
     "start_time": "2025-05-10T10:06:09.075460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Bar, Pie, Grid, Page, Tab, Scatter\n",
    "from pyecharts.components import Table\n",
    "from pyecharts.globals import ThemeType\n",
    "from pyecharts.commons.utils import JsCode"
   ],
   "id": "ac92d516c77dab44",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:06:10.832347Z",
     "start_time": "2025-05-10T10:06:10.807943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_txt_report(file_path):\n",
    "    \"\"\"读取分析报告TXT文件并解析其内容\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 提取标题\n",
    "    title_match = re.search(r\"Keyword Analysis Report: '(.+)'\", content)\n",
    "    title = title_match.group(1) if title_match else \"Unknown Keyword\"\n",
    "\n",
    "    # 解析共现关键词\n",
    "    cooccurring_section = re.search(r\"1\\. Top 10 Co-occurring Keywords:\\n-+\\n(.*?)(?=\\n\\n\\d\\.)\", content, re.DOTALL)\n",
    "    cooccurring_keywords = []\n",
    "\n",
    "    if cooccurring_section:\n",
    "        lines = cooccurring_section.group(1).strip().split('\\n')\n",
    "        for line in lines:\n",
    "            if \"No co-occurring keywords found\" in line:\n",
    "                break\n",
    "            match = re.search(r\"\\d+\\. (.+) \\(Count: (\\d+)\\)\", line)\n",
    "            if match:\n",
    "                keyword, count = match.groups()\n",
    "                cooccurring_keywords.append((keyword, int(count)))\n",
    "\n",
    "    # 解析所有时期的高引论文\n",
    "    all_time_papers_section = re.search(r\"2\\. Top 5 Highly Cited Papers \\(All Time\\):\\n-+\\n(.*?)(?=\\n\\n\\d\\.)\", content, re.DOTALL)\n",
    "    all_time_papers = []\n",
    "\n",
    "    if all_time_papers_section:\n",
    "        papers_text = all_time_papers_section.group(1)\n",
    "        if \"No papers found\" not in papers_text:\n",
    "            paper_blocks = re.findall(r\"(\\d+\\. Title:.+?)(?=\\n\\d+\\. Title:|$)\", papers_text, re.DOTALL)\n",
    "\n",
    "            for block in paper_blocks:\n",
    "                title_match = re.search(r\"Title: (.+)\", block)\n",
    "                authors_match = re.search(r\"Authors: (.+)\", block)\n",
    "                year_match = re.search(r\"Year: (.+)\", block)\n",
    "                citations_match = re.search(r\"Citations: (.+)\", block)\n",
    "                doi_match = re.search(r\"DOI: (.+)\", block)\n",
    "\n",
    "                paper = {\n",
    "                    \"title\": title_match.group(1) if title_match else \"N/A\",\n",
    "                    \"authors\": authors_match.group(1) if authors_match else \"N/A\",\n",
    "                    \"year\": year_match.group(1) if year_match else \"N/A\",\n",
    "                    \"citations\": citations_match.group(1) if citations_match else \"0\",\n",
    "                    \"doi\": doi_match.group(1) if doi_match else \"N/A\"\n",
    "                }\n",
    "                all_time_papers.append(paper)\n",
    "\n",
    "    # 解析近3年的高引论文\n",
    "    recent_papers_section = re.search(r\"3\\. Top 5 Highly Cited Papers \\(Last 3 Years.+?\\):\\n-+\\n(.*?)(?=\\n\\n\\d\\.)\", content, re.DOTALL)\n",
    "    recent_papers = []\n",
    "\n",
    "    if recent_papers_section:\n",
    "        papers_text = recent_papers_section.group(1)\n",
    "        if \"No recent papers found\" not in papers_text:\n",
    "            paper_blocks = re.findall(r\"(\\d+\\. Title:.+?)(?=\\n\\d+\\. Title:|$)\", papers_text, re.DOTALL)\n",
    "\n",
    "            for block in paper_blocks:\n",
    "                title_match = re.search(r\"Title: (.+)\", block)\n",
    "                authors_match = re.search(r\"Authors: (.+)\", block)\n",
    "                year_match = re.search(r\"Year: (.+)\", block)\n",
    "                citations_match = re.search(r\"Citations: (.+)\", block)\n",
    "                doi_match = re.search(r\"DOI: (.+)\", block)\n",
    "\n",
    "                paper = {\n",
    "                    \"title\": title_match.group(1) if title_match else \"N/A\",\n",
    "                    \"authors\": authors_match.group(1) if authors_match else \"N/A\",\n",
    "                    \"year\": year_match.group(1) if year_match else \"N/A\",\n",
    "                    \"citations\": citations_match.group(1) if citations_match else \"0\",\n",
    "                    \"doi\": doi_match.group(1) if doi_match else \"N/A\"\n",
    "                }\n",
    "                recent_papers.append(paper)\n",
    "\n",
    "    # 解析顶级机构\n",
    "    institutions_section = re.search(r\"4\\. Top Institutions Publishing Papers on this Keyword:\\n-+\\n(.*?)(?=$)\", content, re.DOTALL)\n",
    "    top_institutions = []\n",
    "\n",
    "    if institutions_section:\n",
    "        lines = institutions_section.group(1).strip().split('\\n')\n",
    "        for line in lines:\n",
    "            if \"No institution data available\" in line:\n",
    "                break\n",
    "            match = re.search(r\"\\d+\\. (.+) \\(Paper Count: (\\d+)\\)\", line)\n",
    "            if match:\n",
    "                institution, count = match.groups()\n",
    "                top_institutions.append((institution, int(count)))\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"cooccurring_keywords\": cooccurring_keywords,\n",
    "        \"all_time_papers\": all_time_papers,\n",
    "        \"recent_papers\": recent_papers,\n",
    "        \"top_institutions\": top_institutions\n",
    "    }"
   ],
   "id": "c336219d0233e315",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:06:26.267673Z",
     "start_time": "2025-05-10T10:06:26.253590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_cooccurring_keywords_colored_list(data, target_keyword):\n",
    "    \"\"\"创建共现关键词彩色列表图表\"\"\"\n",
    "    if not data:\n",
    "        return None\n",
    "\n",
    "    # 计算最大值和最小值以正确设置颜色\n",
    "    max_count = max([item[1] for item in data]) if data else 0\n",
    "    min_count = min([item[1] for item in data]) if data else 0\n",
    "\n",
    "    # 准备数据，添加目标关键词作为中心节点\n",
    "    nodes_data = [{\"name\": target_keyword, \"symbolSize\": 40, \"value\": max_count + 5, \"category\": 0}]\n",
    "    links_data = []\n",
    "\n",
    "    for i, (keyword, count) in enumerate(data):\n",
    "        # 计算节点大小，值从最小值到最大值之间映射到20-35之间\n",
    "        size = 20 + (count - min_count) * 15 / (max_count - min_count + 0.1)\n",
    "        nodes_data.append({\n",
    "            \"name\": keyword,\n",
    "            \"symbolSize\": size,\n",
    "            \"value\": count,\n",
    "            \"category\": 1\n",
    "        })\n",
    "\n",
    "        # 添加与中心节点的连接\n",
    "        links_data.append({\n",
    "            \"source\": target_keyword,\n",
    "            \"target\": keyword,\n",
    "            \"value\": count\n",
    "        })\n",
    "\n",
    "    c = (\n",
    "        Scatter()\n",
    "        .add_xaxis([item[0] for item in data])\n",
    "        .add_yaxis(\n",
    "            series_name=\"\",\n",
    "            y_axis=[item[1] for item in data],\n",
    "            symbol_size=15,\n",
    "            label_opts=opts.LabelOpts(\n",
    "                is_show=True,\n",
    "                position=\"right\",\n",
    "                formatter=JsCode(\n",
    "                    \"function(params){return params.value[0] + ': ' + params.value[1];}\"\n",
    "                ),\n",
    "                font_size=12,\n",
    "                color=\"auto\",\n",
    "            ),\n",
    "            itemstyle_opts=opts.ItemStyleOpts(\n",
    "                color=JsCode(\n",
    "                    \"\"\"\n",
    "                    function(params) {\n",
    "                        var colorList = ['#c23531','#2f4554','#61a0a8','#d48265','#91c7ae',\n",
    "                        '#749f83','#ca8622','#bda29a','#6e7074','#546570','#c4ccd3'];\n",
    "                        var value = params.data[1];\n",
    "                        var maxVal = \"\"\" + str(max_count) + \"\"\";\n",
    "                        var minVal = \"\"\" + str(min_count) + \"\"\";\n",
    "                        var normalizedValue = (value - minVal) / (maxVal - minVal);\n",
    "\n",
    "                        var r = Math.round(normalizedValue * 255);\n",
    "                        var g = Math.round(100 + (1-normalizedValue) * 155);\n",
    "                        var b = Math.round(50 + (1-normalizedValue) * 205);\n",
    "\n",
    "                        return 'rgb(' + r + ',' + g + ',' + b + ')';\n",
    "                    }\n",
    "                    \"\"\"\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(\n",
    "                title=f\"Co-occurring Keywords with '{target_keyword}'\",\n",
    "                subtitle=\"Circle color indicates frequency (darker = higher frequency)\"\n",
    "            ),\n",
    "            xaxis_opts=opts.AxisOpts(\n",
    "                type_=\"value\",\n",
    "                is_show=False,\n",
    "            ),\n",
    "            yaxis_opts=opts.AxisOpts(\n",
    "                type_=\"value\",\n",
    "                is_show=False,\n",
    "            ),\n",
    "            tooltip_opts=opts.TooltipOpts(\n",
    "                formatter=JsCode(\n",
    "                    \"function(params){return params.name + ': ' + params.value[1];}\"\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return c"
   ],
   "id": "4f5200b9be5520cc",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:06:31.423477Z",
     "start_time": "2025-05-10T10:06:31.409396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_paper_table(papers, title):\n",
    "    \"\"\"创建论文表格\"\"\"\n",
    "    if not papers:\n",
    "        return None\n",
    "\n",
    "    table = Table()\n",
    "    headers = [\"Title\", \"Authors\", \"Year\", \"Citations\", \"DOI\"]\n",
    "    rows = []\n",
    "\n",
    "    for paper in papers:\n",
    "        rows.append([\n",
    "            paper[\"title\"],\n",
    "            paper[\"authors\"],\n",
    "            paper[\"year\"],\n",
    "            paper[\"citations\"],\n",
    "            paper[\"doi\"]\n",
    "        ])\n",
    "\n",
    "    table.add(headers, rows)\n",
    "    table.set_global_opts(\n",
    "        title_opts=opts.ComponentTitleOpts(title=title)\n",
    "    )\n",
    "\n",
    "    return table"
   ],
   "id": "38d764260d2f950a",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:06:36.942713Z",
     "start_time": "2025-05-10T10:06:36.928503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_institutions_chart(data):\n",
    "    \"\"\"创建顶级机构图表\"\"\"\n",
    "    if not data:\n",
    "        return None\n",
    "\n",
    "    institutions = [item[0][:30] + \"...\" if len(item[0]) > 30 else item[0] for item in data]\n",
    "    counts = [item[1] for item in data]\n",
    "\n",
    "    c = (\n",
    "        Bar()\n",
    "        .add_xaxis(institutions[::-1])\n",
    "        .add_yaxis(\"Paper Count\", counts[::-1], category_gap=\"50%\")\n",
    "        .reversal_axis()\n",
    "        .set_series_opts(label_opts=opts.LabelOpts(position=\"right\"))\n",
    "        .set_global_opts(\n",
    "            title_opts=opts.TitleOpts(title=\"Top Institutions\"),\n",
    "            xaxis_opts=opts.AxisOpts(name=\"Institutions\"),\n",
    "            yaxis_opts=opts.AxisOpts(name=\"Paper Count\"),\n",
    "            toolbox_opts=opts.ToolboxOpts(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return c"
   ],
   "id": "2ae2615d9493aa12",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:06:41.836995Z",
     "start_time": "2025-05-10T10:06:41.822807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_keyword_page(report_data):\n",
    "    \"\"\"为每个关键词创建可视化页面\"\"\"\n",
    "    page = Page(layout=Page.DraggablePageLayout)\n",
    "\n",
    "    # 添加共现关键词彩色列表图表\n",
    "    keyword_chart = create_cooccurring_keywords_colored_list(\n",
    "        report_data[\"cooccurring_keywords\"],\n",
    "        report_data[\"title\"]\n",
    "    )\n",
    "    if keyword_chart:\n",
    "        page.add(keyword_chart)\n",
    "\n",
    "    # 添加所有时期高引论文表格\n",
    "    all_time_table = create_paper_table(\n",
    "        report_data[\"all_time_papers\"],\n",
    "        \"Top Highly Cited Papers (All Time)\"\n",
    "    )\n",
    "    if all_time_table:\n",
    "        page.add(all_time_table)\n",
    "\n",
    "    # 添加近3年高引论文表格\n",
    "    recent_table = create_paper_table(\n",
    "        report_data[\"recent_papers\"],\n",
    "        \"Top Highly Cited Papers (Recent 3 Years)\"\n",
    "    )\n",
    "    if recent_table:\n",
    "        page.add(recent_table)\n",
    "\n",
    "    # 添加顶级机构图表\n",
    "    institutions_chart = create_institutions_chart(report_data[\"top_institutions\"])\n",
    "    if institutions_chart:\n",
    "        page.add(institutions_chart)\n",
    "\n",
    "    return page"
   ],
   "id": "8b6819a42e6faaee",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:06:47.126126Z",
     "start_time": "2025-05-10T10:06:47.112946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_html_dashboard(txt_files, output_file):\n",
    "    \"\"\"生成HTML仪表板，整合所有关键词的分析结果\"\"\"\n",
    "    tab = Tab()\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        # 读取TXT报告\n",
    "        report_data = read_txt_report(txt_file)\n",
    "        keyword = report_data[\"title\"]\n",
    "\n",
    "        # 创建关键词页面\n",
    "        keyword_page = create_keyword_page(report_data)\n",
    "\n",
    "        # 添加到标签页\n",
    "        tab.add(keyword, keyword_page)\n",
    "\n",
    "    # 保存为HTML文件\n",
    "    tab.render(output_file)\n",
    "    print(f\"已生成HTML仪表板: {output_file}\")"
   ],
   "id": "9ec9bfd97f6fc40e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T10:07:13.248790Z",
     "start_time": "2025-05-10T10:07:12.938687Z"
    }
   },
   "cell_type": "code",
   "source": "generate_html_dashboard(html_source_files, output_file)",
   "id": "91ee0a80a3df5416",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tab_name'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mgenerate_html_dashboard\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhtml_source_files\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[28], line 14\u001B[0m, in \u001B[0;36mgenerate_html_dashboard\u001B[1;34m(txt_files, output_file)\u001B[0m\n\u001B[0;32m     11\u001B[0m     keyword_page \u001B[38;5;241m=\u001B[39m create_keyword_page(report_data)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# 添加到标签页\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m     \u001B[43mtab\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeyword_page\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# 保存为HTML文件\u001B[39;00m\n\u001B[0;32m     17\u001B[0m tab\u001B[38;5;241m.\u001B[39mrender(output_file)\n",
      "File \u001B[1;32mD:\\software\\miniconda3\\envs\\literature-analysis\\lib\\site-packages\\pyecharts\\charts\\composite_charts\\tab.py:74\u001B[0m, in \u001B[0;36mTab.add\u001B[1;34m(self, chart, tab_name)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21madd\u001B[39m(\u001B[38;5;28mself\u001B[39m, chart, tab_name):\n\u001B[1;32m---> 74\u001B[0m     \u001B[43mchart\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtab_name\u001B[49m \u001B[38;5;241m=\u001B[39m tab_name\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_charts\u001B[38;5;241m.\u001B[39mappend(chart)\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m chart\u001B[38;5;241m.\u001B[39mjs_dependencies\u001B[38;5;241m.\u001B[39mitems:\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'tab_name'"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2beda427f5febc50"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
